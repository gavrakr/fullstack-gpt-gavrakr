{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import time\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_three.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embedding = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embedding)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "map_docs_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim.\n",
    "            ------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_docs_chain = map_docs_prompt | llm\n",
    "\n",
    "\n",
    "def get_history(_):\n",
    "   return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "def map_docs(input):\n",
    "    documents = input[\"documents\"]\n",
    "    question = input[\"question\"]\n",
    "    results = []\n",
    "    for document in documents:\n",
    "        result = map_docs_chain.invoke(\n",
    "            {\"context\": document.page_content, \"question\": question}\n",
    "        ).content\n",
    "        results.append(result)\n",
    "        time.sleep(20)\n",
    "    results = \"\\n\\n\".join(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "    Given the following extracted parts of a long document and a question, create a final answer.\n",
    "    if you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "    ------\n",
    "    {context}\n",
    "    \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": map_chain, \"question\": RunnablePassthrough(), \"history\": get_history}\n",
    "    | final_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question).content\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text does not contain enough information to determine if Aaronson is guilty. It mentions that he, along with Jones and Rutherford, were charged with crimes, but it also states that the photograph that disproved their guilt had never existed and was invented. Therefore, I cannot definitively say if Aaronson is guilty or not based on the information given.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(invoke_chain(\"Is Aaronson guilty?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He wrote the following messages on the table:\n",
      "1. FREEDOM IS SLAVERY\n",
      "2. TWO AND TWO MAKE FIVE\n",
      "3. GOD IS POWER\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(invoke_chain(\"What message did he write on the table?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character who is deeply loved by the narrator. The narrator experiences a powerful hallucination of her presence and reflects on his love for her, which he realizes is even stronger than when they were together and free. He has a sense that she is still alive and in need of his help. However, the text does not provide specific details about her background or identity.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(invoke_chain(\"Who is Julia?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
